{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "910bf724-88ba-4e2e-96e9-e9accbea90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import dotenv\n",
    "import openai\n",
    "from datetime import date\n",
    "import requests\n",
    "from openai import AzureOpenAI\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "endpoint = os.environ.get(\"FTQ_AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.environ.get(\"FTQ_AZURE_OPENAI_API_KEY\")\n",
    "deployment = os.environ.get(\"FTQ_AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "api_version = os.environ.get(\"FTQ_AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "client = openai.AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=api_key,\n",
    "    api_version=api_version,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "869369aa-09f6-4240-901b-df9a71c1cc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in training set: 10\n",
      "First example in training set:\n",
      "{'role': 'system', 'content': 'Clippy is a factual chatbot that is also sarcastic.'}\n",
      "{'role': 'user', 'content': 'Who discovered Antarctica?'}\n",
      "{'role': 'assistant', 'content': \"Some chaps named Fabian Gottlieb von Bellingshausen and Mikhail Lazarev, as if they don't teach that in every school!\"}\n",
      "\n",
      "Number of examples in validation set: 10\n",
      "First example in validation set:\n",
      "{'role': 'system', 'content': 'Clippy is a factual chatbot that is also sarcastic.'}\n",
      "{'role': 'user', 'content': \"What's the capital of Australia?\"}\n",
      "{'role': 'assistant', 'content': \"It's Canberra, not Sydney. Shocking, I know!\"}\n"
     ]
    }
   ],
   "source": [
    "# Run preliminary checks\n",
    "\n",
    "import json\n",
    "\n",
    "# Load the training set\n",
    "with open('training_set.jsonl', 'r', encoding='utf-8') as f:\n",
    "    training_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in training set:\", len(training_dataset))\n",
    "print(\"First example in training set:\")\n",
    "for message in training_dataset[0][\"messages\"]:\n",
    "    print(message)\n",
    "\n",
    "# Load the validation set\n",
    "with open('validation_set.jsonl', 'r', encoding='utf-8') as f:\n",
    "    validation_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Validation dataset stats\n",
    "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
    "print(\"First example in validation set:\")\n",
    "for message in validation_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ec47166-b42b-40fd-964f-395aa55725a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: training_set.jsonl\n",
      "\n",
      "#### Distribution of total tokens:\n",
      "min / max: 46, 59\n",
      "mean / median: 49.8, 48.5\n",
      "p5 / p95: 46.0, 53.599999999999994\n",
      "\n",
      "#### Distribution of assistant tokens:\n",
      "min / max: 13, 28\n",
      "mean / median: 16.5, 14.0\n",
      "p5 / p95: 13.0, 19.9\n",
      "**************************************************\n",
      "Processing file: validation_set.jsonl\n",
      "\n",
      "#### Distribution of total tokens:\n",
      "min / max: 41, 64\n",
      "mean / median: 48.9, 47.0\n",
      "p5 / p95: 43.7, 54.099999999999994\n",
      "\n",
      "#### Distribution of assistant tokens:\n",
      "min / max: 8, 29\n",
      "mean / median: 15.0, 12.5\n",
      "p5 / p95: 10.7, 19.999999999999996\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Validate token counts\n",
    "\n",
    "import json\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"o200k_base\") # default encoding for gpt-4o models. This requires the latest version of tiktoken to be installed.\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "files = ['training_set.jsonl', 'validation_set.jsonl']\n",
    "\n",
    "for file in files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "\n",
    "    total_tokens = []\n",
    "    assistant_tokens = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        messages = ex.get(\"messages\", {})\n",
    "        total_tokens.append(num_tokens_from_messages(messages))\n",
    "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "    print_distribution(total_tokens, \"total tokens\")\n",
    "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
    "    print('*' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27c19480-b3ca-46b3-9f40-ef7660908830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-a2dda6c9c2fe43639eabd61f0a9d0167\n",
      "Validation file ID: file-2bf0bf40e65d41c287f6252094aa144d\n"
     ]
    }
   ],
   "source": [
    "training_file_name = 'training_set.jsonl'\n",
    "validation_file_name = 'validation_set.jsonl'\n",
    "\n",
    "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
    "\n",
    "training_response = client.files.create(\n",
    "    file = open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response.id\n",
    "\n",
    "validation_response = client.files.create(\n",
    "    file = open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9daf588a-8905-49d5-b524-2022a0b42a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-08832bd28a9b411f816e6146af2b6bf0\n",
      "Status: pending\n",
      "{\n",
      "  \"id\": \"ftjob-08832bd28a9b411f816e6146af2b6bf0\",\n",
      "  \"created_at\": 1729389163,\n",
      "  \"error\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"finished_at\": null,\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": -1,\n",
      "    \"batch_size\": -1,\n",
      "    \"learning_rate_multiplier\": 1\n",
      "  },\n",
      "  \"model\": \"gpt-35-turbo-0125\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": null,\n",
      "  \"result_files\": null,\n",
      "  \"seed\": 105,\n",
      "  \"status\": \"pending\",\n",
      "  \"trained_tokens\": null,\n",
      "  \"training_file\": \"file-a2dda6c9c2fe43639eabd61f0a9d0167\",\n",
      "  \"validation_file\": \"file-2bf0bf40e65d41c287f6252094aa144d\",\n",
      "  \"estimated_finish\": null,\n",
      "  \"integrations\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Submit fine-tuning training job\n",
    "\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file = training_file_id,\n",
    "    validation_file = validation_file_id,\n",
    "    model = \"gpt-35-turbo-0125\", # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters.\n",
    "    seed = 105 # seed parameter controls reproducibility of the fine-tuning job. If no seed is specified one will be generated automatically.\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b01493df-1a56-40fa-994f-8fcfa61b67b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job ftjob-08832bd28a9b411f816e6146af2b6bf0 finished with status: succeeded\n",
      "Checking other fine-tune jobs for this resource.\n",
      "Found 1 fine-tune jobs.\n"
     ]
    }
   ],
   "source": [
    "# Track training status\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "status = response.status\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(10)\n",
    "\n",
    "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = response.status\n",
    "    print(f'Status: {status}')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f'Fine-tuning job {job_id} finished with status: {status}')\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print('Checking other fine-tune jobs for this resource.')\n",
    "response = client.fine_tuning.jobs.list()\n",
    "print(f'Found {len(response.data)} fine-tune jobs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd615878-040e-42e3-8060-39df6f53ae42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"ftevent-df29c4eb48a1446cb29f4e320ef7b5a7\",\n",
      "      \"created_at\": 1729391315,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Training tokens billed: 6000\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"message\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-17ea47ae9fac4738b95967e96552b905\",\n",
      "      \"created_at\": 1729391315,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Completed results file: file-706c75feef63450285e4a4ac2f2fe587\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"message\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-f280eba83ad644c5baa6ab1944e95393\",\n",
      "      \"created_at\": 1729391262,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job succeeded.\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"message\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-008dcf0ae077743008dcf0ae07774300\",\n",
      "      \"created_at\": 1729390942,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 100: training loss=0.11779531091451645\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"metrics\",\n",
      "      \"data\": {\n",
      "        \"step\": 100,\n",
      "        \"train_loss\": 0.11779531091451645,\n",
      "        \"train_mean_token_accuracy\": 1,\n",
      "        \"valid_loss\": 1.6439884185791016,\n",
      "        \"valid_mean_token_accuracy\": 0.7,\n",
      "        \"full_valid_loss\": 1.1610899983837617,\n",
      "        \"full_valid_mean_token_accuracy\": 0.7262569832402235\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-008dcf0ae018162008dcf0ae01816200\",\n",
      "      \"created_at\": 1729390932,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 90: training loss=0.029918882995843887\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"metrics\",\n",
      "      \"data\": {\n",
      "        \"step\": 90,\n",
      "        \"train_loss\": 0.029918882995843887,\n",
      "        \"train_mean_token_accuracy\": 1,\n",
      "        \"valid_loss\": 1.562799072265625,\n",
      "        \"valid_mean_token_accuracy\": 0.7,\n",
      "        \"full_valid_loss\": 1.1528678712898126,\n",
      "        \"full_valid_mean_token_accuracy\": 0.7262569832402235\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-008dcf0adfb8b81008dcf0adfb8b8100\",\n",
      "      \"created_at\": 1729390922,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 80: training loss=0.40369370579719543\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"metrics\",\n",
      "      \"data\": {\n",
      "        \"step\": 80,\n",
      "        \"train_loss\": 0.40369370579719543,\n",
      "        \"train_mean_token_accuracy\": 0.9090909361839294,\n",
      "        \"valid_loss\": 1.3590259552001953,\n",
      "        \"valid_mean_token_accuracy\": 0.8,\n",
      "        \"full_valid_loss\": 1.1324998812968505,\n",
      "        \"full_valid_mean_token_accuracy\": 0.7318435754189944\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-008dcf0adf595a0008dcf0adf595a000\",\n",
      "      \"created_at\": 1729390912,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 70: training loss=0.5818624496459961\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"metrics\",\n",
      "      \"data\": {\n",
      "        \"step\": 70,\n",
      "        \"train_loss\": 0.5818624496459961,\n",
      "        \"train_mean_token_accuracy\": 0.84375,\n",
      "        \"valid_loss\": 1.3039852142333985,\n",
      "        \"valid_mean_token_accuracy\": 0.8,\n",
      "        \"full_valid_loss\": 1.1106041796380581,\n",
      "        \"full_valid_mean_token_accuracy\": 0.7486033519553073\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-008dcf0adef9fbf008dcf0adef9fbf00\",\n",
      "      \"created_at\": 1729390902,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 60: training loss=0.31397369503974915\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"metrics\",\n",
      "      \"data\": {\n",
      "        \"step\": 60,\n",
      "        \"train_loss\": 0.31397369503974915,\n",
      "        \"train_mean_token_accuracy\": 0.9411764740943909,\n",
      "        \"valid_loss\": 1.1474889755249023,\n",
      "        \"valid_mean_token_accuracy\": 0.9,\n",
      "        \"full_valid_loss\": 1.0926598010782422,\n",
      "        \"full_valid_mean_token_accuracy\": 0.7318435754189944\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-008dcf0ade9a9de008dcf0ade9a9de00\",\n",
      "      \"created_at\": 1729390892,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 50: training loss=0.3325997591018677\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"metrics\",\n",
      "      \"data\": {\n",
      "        \"step\": 50,\n",
      "        \"train_loss\": 0.3325997591018677,\n",
      "        \"train_mean_token_accuracy\": 0.8666666746139526,\n",
      "        \"valid_loss\": 1.1135303497314453,\n",
      "        \"valid_mean_token_accuracy\": 0.9,\n",
      "        \"full_valid_loss\": 1.0923181619058109,\n",
      "        \"full_valid_mean_token_accuracy\": 0.7374301675977654\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-008dcf0ade3b3fd008dcf0ade3b3fd00\",\n",
      "      \"created_at\": 1729390882,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 40: training loss=0.6051002740859985\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"metrics\",\n",
      "      \"data\": {\n",
      "        \"step\": 40,\n",
      "        \"train_loss\": 0.6051002740859985,\n",
      "        \"train_mean_token_accuracy\": 0.7647058963775635,\n",
      "        \"valid_loss\": 1.146611785888672,\n",
      "        \"valid_mean_token_accuracy\": 0.7,\n",
      "        \"full_valid_loss\": 1.0814214631831847,\n",
      "        \"full_valid_mean_token_accuracy\": 0.7318435754189944\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"has_more\": true,\n",
      "  \"object\": \"list\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#List fine-tuning events\n",
    "#API version: 2024-08-01-preview or later is required for this command.\n",
    "\n",
    "#While not necessary to complete fine-tuning it can be helpful to examine the individual fine-tuning events that were generated during training. \n",
    "#The full training results can also be examined after training is complete in the training results file.\n",
    "\n",
    "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1df607ec-0acc-4dc3-8af0-ebc87196d383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"ftchkpt-52916a1b07de49cb8e7c57ca3d864e22\",\n",
      "      \"created_at\": 1729391006,\n",
      "      \"fine_tuned_model_checkpoint\": \"gpt-35-turbo-0125.ft-08832bd28a9b411f816e6146af2b6bf0\",\n",
      "      \"fine_tuning_job_id\": \"ftjob-08832bd28a9b411f816e6146af2b6bf0\",\n",
      "      \"metrics\": {\n",
      "        \"full_valid_loss\": 1.1610899983837617,\n",
      "        \"full_valid_mean_token_accuracy\": 0.7262569832402235,\n",
      "        \"step\": 100.0,\n",
      "        \"train_loss\": 0.11779531091451645,\n",
      "        \"train_mean_token_accuracy\": 1.0,\n",
      "        \"valid_loss\": 1.6439884185791016,\n",
      "        \"valid_mean_token_accuracy\": 0.7\n",
      "      },\n",
      "      \"object\": \"fine_tuning.job.checkpoint\",\n",
      "      \"step_number\": 100\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftchkpt-6fe974c891dd4f358569e685b5d805aa\",\n",
      "      \"created_at\": 1729390991,\n",
      "      \"fine_tuned_model_checkpoint\": \"gpt-35-turbo-0125.ft-08832bd28a9b411f816e6146af2b6bf0:ckpt-step-90\",\n",
      "      \"fine_tuning_job_id\": \"ftjob-08832bd28a9b411f816e6146af2b6bf0\",\n",
      "      \"metrics\": {\n",
      "        \"full_valid_loss\": 1.1528678712898126,\n",
      "        \"full_valid_mean_token_accuracy\": 0.7262569832402235,\n",
      "        \"step\": 90.0,\n",
      "        \"train_loss\": 0.029918882995843887,\n",
      "        \"train_mean_token_accuracy\": 1.0,\n",
      "        \"valid_loss\": 1.562799072265625,\n",
      "        \"valid_mean_token_accuracy\": 0.7\n",
      "      },\n",
      "      \"object\": \"fine_tuning.job.checkpoint\",\n",
      "      \"step_number\": 90\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftchkpt-08f4476300e548ffa938fa684763ea68\",\n",
      "      \"created_at\": 1729390976,\n",
      "      \"fine_tuned_model_checkpoint\": \"gpt-35-turbo-0125.ft-08832bd28a9b411f816e6146af2b6bf0:ckpt-step-80\",\n",
      "      \"fine_tuning_job_id\": \"ftjob-08832bd28a9b411f816e6146af2b6bf0\",\n",
      "      \"metrics\": {\n",
      "        \"full_valid_loss\": 1.1324998812968505,\n",
      "        \"full_valid_mean_token_accuracy\": 0.7318435754189944,\n",
      "        \"step\": 80.0,\n",
      "        \"train_loss\": 0.40369370579719543,\n",
      "        \"train_mean_token_accuracy\": 0.9090909361839294,\n",
      "        \"valid_loss\": 1.3590259552001953,\n",
      "        \"valid_mean_token_accuracy\": 0.8\n",
      "      },\n",
      "      \"object\": \"fine_tuning.job.checkpoint\",\n",
      "      \"step_number\": 80\n",
      "    }\n",
      "  ],\n",
      "  \"has_more\": false,\n",
      "  \"object\": \"list\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#List checkpoints\n",
    "#API version: 2024-08-01-preview or later is required for this command.\n",
    "\n",
    "#When each training epoch completes a checkpoint is generated.\n",
    "#A checkpoint is a fully functional version of a model which can both be deployed and used as the target model for subsequent fine-tuning jobs.\n",
    "#Checkpoints can be particularly useful, as they can provide a snapshot of your model prior to overfitting having occurred. \n",
    "#When a fine-tuning job completes you will have the three most recent versions of the model available to deploy. \n",
    "#The final epoch will be represented by your fine-tuned model, the previous two epochs will be available as checkpoints.\n",
    "\n",
    "response = client.fine_tuning.jobs.checkpoints.list(job_id)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85377dbe-c02c-46e6-80cf-f602d0a72ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"ftjob-08832bd28a9b411f816e6146af2b6bf0\",\n",
      "  \"created_at\": 1729389163,\n",
      "  \"error\": null,\n",
      "  \"fine_tuned_model\": \"gpt-35-turbo-0125.ft-08832bd28a9b411f816e6146af2b6bf0\",\n",
      "  \"finished_at\": 1729391315,\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 10,\n",
      "    \"batch_size\": 1,\n",
      "    \"learning_rate_multiplier\": 1\n",
      "  },\n",
      "  \"model\": \"gpt-35-turbo-0125\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": null,\n",
      "  \"result_files\": [\n",
      "    \"file-706c75feef63450285e4a4ac2f2fe587\"\n",
      "  ],\n",
      "  \"seed\": 105,\n",
      "  \"status\": \"succeeded\",\n",
      "  \"trained_tokens\": 5210,\n",
      "  \"training_file\": \"file-a2dda6c9c2fe43639eabd61f0a9d0167\",\n",
      "  \"validation_file\": \"file-2bf0bf40e65d41c287f6252094aa144d\",\n",
      "  \"estimated_finish\": null,\n",
      "  \"integrations\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#Final training run results\n",
    "#To get the final results, run the following:\n",
    "# Retrieve fine_tuned_model name\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(response.model_dump_json(indent=2))\n",
    "fine_tuned_model = response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f43bd-9455-4bde-a73e-39f18f9d1988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
